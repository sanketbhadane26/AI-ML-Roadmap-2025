# Day 2 — Tree Models (Decision Trees & Random Forest)

## ✔ Concepts Learned
- Decision Trees: entropy, gini, information gain
- Random Forest: bagging, feature randomness
- Hyperparameters: n_estimators, max_depth, max_features, min_samples_split
- Overfitting vs generalization
- Feature importance visualization
- Confusion matrix & classification report

## ✔ Implemented
- DecisionTreeClassifier (entropy & gini)
- RandomForestClassifier with tuned hyperparameters
- Model evaluation & comparison
- Feature importance plots
- Confusion matrix heatmap

## Files
- Day2_Tree_Models.ipynb
